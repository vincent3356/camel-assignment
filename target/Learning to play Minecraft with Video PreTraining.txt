Learning to play Minecraft with Video PreTraining
Jun 23, 2022June 23, 2022
 Pretraining on noisy, internet-scale datasets has been heavily studied as a
technique for training models with broad, general capabilities for text,
images, and other modalities. However, for many sequential decision domains
such as robotics, video games, and computer use, publicly available data does
not contain the labels required to train behavioral priors in the same way. We
extend the internet-scale pretraining paradigm to sequential decision domains
through semi-supervised imitation learning wherein agents learn to act by
watching online unlabeled videos. Specifically, we show that with a small
amount of labeled data we can train an inverse dynamics model accurate enough
to label a huge unlabeled source of online data -- here, online videos of
people playing Minecraft -- from which we can then train a general behavioral
prior. Despite using the native human interface (mouse and keyboard at 20Hz),
we show that this behavioral prior has nontrivial zero-shot capabilities and
that it can be fine-tuned, with both imitation learning and reinforcement
learning, to hard-exploration tasks that are impossible to learn from scratch
via reinforcement learning. For many tasks our models exhibit human-level
performance, and we are the first to report computer agents that can craft
diamond tools, which can take proficient humans upwards of 20 minutes (24,000
environment actions) of gameplay to accomplish.

Bowen Baker,Jeff Clune,Brandon Houghton,Joost Huizinga,Peter Zhokhov,Jie Tang,Raul Sampedro,Adrien Ecoffet,Ilge Akkaya,
https://scholar.google.com/citations?user=bMfPYdYAAAAJ&hl=en,https://www.researchgate.net/scientific-contributions/Bowen-Baker-2159780115,https://paperswithcode.com/author/bowen-baker,https://www.semanticscholar.org/author/Bowen-Baker/40566201,https://www.amazon.com/Bowen-Technique-Julian-Baker/dp/1903333067
http://jeffclune.com/,http://jeffclune.com/media/Jeff-Clune-CV.pdf,https://scholar.google.com/citations?user=5TZ7f5wAAAAJ&hl=en,https://twitter.com/jeffclune?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor,https://ieeexplore.ieee.org/author/37706133600
https://scholar.google.com/citations?user=19QZQu4AAAAJ&hl=en,https://www.researchgate.net/scientific-contributions/Brandon-Houghton-2156362610,https://dl.acm.org/do/10.1145/contrib-99659843384/abs/,https://paperswithcode.com/author/brandon-houghton,https://deepai.org/profile/brandon-houghton
https://www.linkedin.com/in/joost-huizinga-95a65463,https://scholar.google.com/citations?user=VPNtfwkAAAAJ&hl=en,https://twitter.com/joost_huizinga?lang=en,https://www.semanticscholar.org/author/Joost-Huizinga/39378983,https://joosthuizinga.github.io/
https://paperswithcode.com/author/peter-zhokhov,https://www.linkedin.com/in/peter-zhokhov-b68525b3,https://www.researchgate.net/profile/Peter-Zhokhov,https://arxiv.org/abs/2106.14876,https://www.cs.ubc.ca/news/2022/11/neurips22-dr-clune-and-co-researchers-land-top-their-game-machine-learning
https://dl.acm.org/profile/81548005696,https://ieeexplore.ieee.org/author/37290459900,https://dblp.org/pid/t/JieTang,https://www.goodreads.com/author/show/856582.Jie_Tang,https://www.semanticscholar.org/author/Jie-Tang/46199760
https://www.linkedin.com/in/sampedro,https://paperswithcode.com/author/raul-sampedro,https://scholar.google.com/citations?user=Bop6iBYAAAAJ&hl=en,https://openai.com/blog/authors/raul/,https://deepai.org/profile/raul-sampedro
https://scholar.google.com/citations?user=FczrreMAAAAJ&hl=en,https://www.linkedin.com/in/aecoffet,https://adrien.ecoffet.com/,https://www.semanticscholar.org/author/Adrien-Ecoffet/66821245,https://www.quora.com/profile/Adrien-Lucas-Ecoffet
https://scholar.google.com/citations?user=09tVzasAAAAJ&hl=en,https://ieeexplore.ieee.org/author/38232117300,https://ilge.github.io/,https://www.semanticscholar.org/author/Ilge-Akkaya/2258629,https://paperswithcode.com/author/ilge-akkaya